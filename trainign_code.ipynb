{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import logging\n",
    "from config import Config  # Configurations (learning rate, batch size, etc.)\n",
    "from training.train import train_model  # Core training function\n",
    "from data_processing.data_loading import prepare_data  # DataLoader setup\n",
    "from models.model import FusionNet  # The TCCT-Net model combining two streams\n",
    "from utils.logger import setup_logging  # Logger setup\n",
    "from utils.seed import set_seed  # Setting random seeds for reproducibility\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Instantiate the Config object\n",
    "config = Config()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device('cuda')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the label file (Replace this path with the actual path to your Excel file)\n",
    "# label_file_path = 'data/train_engagement_labels.xlsx'  # Update with the correct path\n",
    "# label_df = pd.read_excel(label_file_path)\n",
    "\n",
    "# # Check the unique values in the 'label' column\n",
    "# unique_labels = label_df['label'].unique()\n",
    "# print(\"Unique labels in the dataset:\", unique_labels)\n",
    "\n",
    "# # Create a label mapping based on the unique labels\n",
    "# label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "# print(\"Label mapping:\", label_mapping)\n",
    "\n",
    "# # Apply the label mapping to convert textual labels to numerical values\n",
    "# label_df['label'] = label_df['label'].map(label_mapping)\n",
    "\n",
    "# # Now the 'label' column contains numeric values based on the mapping\n",
    "# print(label_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# from data_processing import load_csv_data, preprocess_data, augment_dataset, EngagementDataset\n",
    "# from data_processing.data_loading import prepare_data\n",
    "\n",
    "# # Custom collate function for padding sequences\n",
    "# def collate_fn(batch):\n",
    "#     data, labels = zip(*batch)\n",
    "#     sequence_lengths = [seq.shape[0] for seq in data]\n",
    "#     data_padded = torch.nn.utils.rnn.pad_sequence(data, batch_first=True)\n",
    "#     labels = torch.stack(labels)\n",
    "#     return data_padded, labels, sequence_lengths\n",
    "\n",
    "# def prepare_data(config):\n",
    "#     # Load file paths and labels from CSVs\n",
    "#     file_paths, labels, feature_columns = load_csv_data(\n",
    "#         folder_path=config.data_dir,\n",
    "#         label_file=config.label_file,\n",
    "#         label_column=config.label_column,\n",
    "#         exclude_columns=config.exclude_columns\n",
    "#     )\n",
    "\n",
    "#     # Preprocess data, now passing the labels as well\n",
    "#     features_list, scaler, feature_names = preprocess_data(\n",
    "#         file_paths, exclude_columns=config.exclude_columns, \n",
    "#         missing_value_strategy=config.missing_value_strategy\n",
    "#     )\n",
    "\n",
    "#     # Split data into train and validation sets\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(\n",
    "#         features_list, labels, test_size=config.test_size, \n",
    "#         stratify=labels, random_state=config.random_state\n",
    "#     )\n",
    "\n",
    "#     # Augment training data\n",
    "#     X_train_augmented, y_train_augmented = augment_dataset(\n",
    "#         X_train, y_train, segment_length=config.segment_length, \n",
    "#         num_augmented_samples=config.num_augmented_samples\n",
    "#     )\n",
    "\n",
    "#     # Create PyTorch Dataset and DataLoader objects\n",
    "#     train_dataset = EngagementDataset(X_train_augmented, y_train_augmented, feature_names, mode='train')\n",
    "#     val_dataset = EngagementDataset(X_val, y_val, feature_names, mode='val')\n",
    "\n",
    "#     train_loader = DataLoader(\n",
    "#         train_dataset, batch_size=config.batch_size, shuffle=True, \n",
    "#         num_workers=config.num_workers, collate_fn=collate_fn, pin_memory=True\n",
    "#     )\n",
    "#     val_loader = DataLoader(\n",
    "#         val_dataset, batch_size=config.batch_size, shuffle=False, \n",
    "#         num_workers=config.num_workers, collate_fn=collate_fn, pin_memory=True\n",
    "#     )\n",
    "\n",
    "#     return train_loader, val_loader, train_dataset, val_dataset\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     train_loader, val_loader, train_dataset, val_dataset = prepare_data(config)\n",
    "#     print(f\"Training data: {len(train_loader.dataset)} samples\")\n",
    "#     print(f\"Validation data: {len(val_loader.dataset)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting File Paths and Labels: 100%|██████████| 15966/15966 [00:10<00:00, 1543.26it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  # Progress bar\n",
    "from data_processing import load_csv_data, preprocess_data, augment_dataset, EngagementDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from training.train import train_model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Initialize logger\n",
    "    logger = setup_logging()\n",
    "\n",
    "    # Prepare data\n",
    "    train_loader, val_loader, train_dataset, val_dataset = prepare_data(config, logger)\n",
    "    logger.info(f\"Training data: {len(train_loader.dataset)} samples\")\n",
    "    logger.info(f\"Validation data: {len(val_loader.dataset)} samples\")\n",
    "    \n",
    "    # Start training\n",
    "    train_model(train_loader, val_loader, config, logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Config object\n",
    "    config = Config()\n",
    "\n",
    "    # Update config with command line arguments\n",
    "    config = update_config_from_args(config, args)\n",
    "\n",
    "    # Set up logging\n",
    "    logger = setup_logging()\n",
    "\n",
    "    # Check and log device usage\n",
    "    check_device(config)\n",
    "    \n",
    "    logger.info(\"Preparing data with the following configuration:\")\n",
    "    for key, value in vars(config).items():\n",
    "        logger.info(f\"{key}: {value}\")\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    set_seed(config.random_seed)\n",
    "\n",
    "    # Prepare data\n",
    "    train_loader, val_loader, train_dataset, val_dataset = prepare_data(config)\n",
    "    \n",
    "    logger.info(f\"Training data: {len(train_loader.dataset)} samples\")\n",
    "    logger.info(f\"Validation data: {len(val_loader.dataset)} samples\")\n",
    "\n",
    "    # Display progress in loading batches\n",
    "    for batch_idx, (data, labels, seq_lengths) in tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Loading Training Data\"):\n",
    "        logger.info(f\"Batch {batch_idx + 1}: Data shape: {data.shape}, Labels shape: {labels.shape}\")\n",
    "\n",
    "    # Insert your training logic here\n",
    "    try:\n",
    "        logger.info(\"Starting training process...\")\n",
    "        train_model(train_loader, val_loader, config)\n",
    "        logger.info(\"Training process completed successfully.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during training: {str(e)}\", exc_info=True)\n",
    "        sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FusionNet (TCCT-Net) model\n",
    "model = FusionNet(config).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging to a file\n",
    "log_file = os.path.join(config.logs_dir, 'training.log')\n",
    "setup_logging(log_file)\n",
    "logging.info(\"Starting training for TCCT-Net model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "set_seed(config.random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the training function\n",
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    config=config,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Integrate TensorBoard for monitoring\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checkpoint import save_checkpoint\n",
    "\n",
    "# Example of saving a checkpoint during training\n",
    "save_checkpoint(model, optimizer, epoch, config.checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluator import evaluate_model\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "evaluate_model(model, val_loader, config, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcct_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
